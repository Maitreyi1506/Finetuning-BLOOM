# Finetuning-BLOOM
BLOOM and MT-0: Large Language Models for Natural Language Processing

Large language models (LLMs) have emerged as powerful tools for natural language processing (NLP) tasks, demonstrating remarkable capabilities in generating text, translating languages, and answering questions. Among the notable LLMs are BLOOM and MT-0, which have garnered attention for their impressive performance and versatility. BLOOM, also known as BigScience Large Open-language Model, is a multilingual and multi-task LLM trained on a massive dataset of text and code in 67 languages. It is characterized by its ability to perform a wide range of NLP tasks. MT-0, also known as Multitask Transformer, is a large language model based on the Transformer architecture. It is trained on a massive dataset of text and code, focusing on few-shot learning, which allows it to perform well on a variety of tasks with minimal training data. MT-0 excels at several NLP tasks.

BLOOM and MT-0 represent significant advancements in NLP technology, demonstrating the potential of LLMs to revolutionize various aspects of human-computer interaction and communication. Their ability to perform a wide range of tasks with impressive accuracy and versatility makes them powerful tools for a variety of applications, promising to shape the future of NLP and beyond.

# IndicQA dataset
The IndicQA dataset is a question answering dataset for Indic languages. It contains over 20,000 questions and answers in five Indic languages: Hindi, Telugu, Bengali, Marathi, and Tamil. The dataset is designed to be challenging for question answering models, as it includes a variety of question types, such as factoid, definitional, and open-ended questions. 

The dataset used in order to finetune the models to Indian languages like we intended to in this project can be found at:
[https://huggingface.co/datasets/ai4bharat/IndicQA](url)
